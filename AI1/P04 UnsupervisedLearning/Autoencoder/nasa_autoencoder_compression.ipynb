{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder (compression)\n",
    "--- \n",
    "\n",
    "In this notebook we will train a fully connected (dense) autoencoder on the nasa data set.\n",
    "\n",
    "The keras code was inspired by https://blog.keras.io/building-autoencoders-in-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inports\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Input, Dense, GaussianNoise\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from util import plot_spectrogram_features\n",
    "from util import plot_reconstruction_error\n",
    "from util import load_data\n",
    "from util import scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary variable\n",
    "tensorboard_path = \"./\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NASA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./features_nasa.pickle\"\n",
    "X_train, X_test = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dim\n",
    "\n",
    "n_features = ... # provide the correct number of features\n",
    "\n",
    "# number of hidden units\n",
    "encoding_dim = 4 # 4 floats --> compression of factor 25, assuming the input is 100 floats\n",
    "\n",
    "print(\"Number of features:\", n_features)\n",
    "print(\"Number of hidden units:\", encoding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(input_shape=(n_features,), units=encoding_dim, activation='sigmoid'))\n",
    "# now the model will take as input arrays of shape (*, n_features)\n",
    "# and output arrays of shape (*, encoding_dim)\n",
    "model.add(Dense(units=..., activation='sigmoid')) # Provide the correct number of output units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer stochastic gradient descent\n",
    "sgd = optimizers.SGD(learning_rate=0.2, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=sgd, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (choose one sensor)\n",
    "nb_sensor = 0\n",
    "x_train = scale(X_train[:,:,nb_sensor])\n",
    "x_test = scale(X_test[:,:,nb_sensor], samples=x_train.shape[0])\n",
    "\n",
    "print(\"Shape of traing set scaled: \\t {}\".format(x_train.shape))\n",
    "print(\"Shape of test set scaled: \\t {}\".format(x_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=20,\n",
    "                shuffle=True,\n",
    "                callbacks=[TensorBoard(log_dir=tensorboard_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "# calculate the reconstruction error\n",
    "costs = np.zeros(x_test.shape[0])\n",
    "for i, x in enumerate(x_test):\n",
    "    input_x = np.reshape(x, (1, x_test.shape[1]))\n",
    "    reconstruction = model.predict(input_x)\n",
    "    # calculate mean squared error\n",
    "    costs[i] = ((x - reconstruction[0]) ** 2).mean(axis=0)\n",
    "\n",
    "plot_reconstruction_error(scale(costs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ki1_labs2]",
   "language": "python",
   "name": "conda-env-ki1_labs2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
